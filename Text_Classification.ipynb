{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Text Classification",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vansh123321/Projects/blob/master/Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89WlSq2ygUIs",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
        "  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Notebook Content</h3>\n",
        "  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"##Library-and-Data\" role=\"tab\" aria-controls=\"profile\">#Library and Data<span class=\"badge badge-primary badge-pill\">1</span></a>\n",
        "  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Reading-Data\" role=\"tab\" aria-controls=\"messages\">Reading Data<span class=\"badge badge-primary badge-pill\">2</span></a>\n",
        "  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#Logistic-Regression-Classifier\" role=\"tab\" aria-controls=\"settings\">Logistic Regression Classifier<span class=\"badge badge-primary badge-pill\">3</span></a>\n",
        "  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Support-Vector-Classifier\" role=\"tab\" aria-controls=\"settings\">Support Vector Classifier<span class=\"badge badge-primary badge-pill\">4</span></a> \n",
        "  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Multinomial-Naive-Bayes-Classifier\" role=\"tab\" aria-controls=\"settings\">Multinomial Naive Bayes Classifier<span class=\"badge badge-primary badge-pill\">5</span></a>\n",
        "    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Bernoulli-Naive-Bayes-Classifier\" role=\"tab\" aria-controls=\"settings\">Bernoulli Naive Bayes Classifier<span class=\"badge badge-primary badge-pill\">6</span></a>\n",
        "    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Gradient-Boost-Classifier\" role=\"tab\" aria-controls=\"settings\">Gradient Boost Classifier<span class=\"badge badge-primary badge-pill\">7</span></a>\n",
        "    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#XGBoost-Classifier\" role=\"tab\" aria-controls=\"settings\">XGBoost Classifier<span class=\"badge badge-primary badge-pill\">8</span></a>  \n",
        "    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Stochastic-Gradient-Descent\" role=\"tab\" aria-controls=\"settings\">Stochastic Gradient Descent<span class=\"badge badge-primary badge-pill\">9</span></a>\n",
        "     <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Decision-Tree\" role=\"tab\" aria-controls=\"settings\">Decision Tree<span class=\"badge badge-primary badge-pill\">10</span></a>\n",
        "     <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#Random-Forest-Classifier\" role=\"tab\" aria-controls=\"settings\">Random Forest Classifier<span class=\"badge badge-primary badge-pill\">11</span></a>\n",
        "     <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#KNN-Classifier\" role=\"tab\" aria-controls=\"settings\">KNN Classifier<span class=\"badge badge-primary badge-pill\">12</span></a>\n",
        "    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#LSTM\" role=\"tab\" aria-controls=\"settings\">LSTM<span class=\"badge badge-primary badge-pill\">12</span></a>\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Amy6tOJLgUIt",
        "colab_type": "text"
      },
      "source": [
        "# Library and Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "JgxQvoETgUIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import EarlyStopping\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "import nltk\n",
        "import nltk as nlp\n",
        "import string\n",
        "import re\n",
        "true = pd.read_csv(\"../input/fake-and-real-news-dataset/True.csv\")\n",
        "fake = pd.read_csv(\"../input/fake-and-real-news-dataset/Fake.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NuMGBpJgUIx",
        "colab_type": "text"
      },
      "source": [
        "# Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hF6Z601vgUIx",
        "colab_type": "code",
        "colab": {},
        "outputId": "54d7d8f3-92cf-46a6-a9cc-f89e57ef67d2"
      },
      "source": [
        "fake['target'] = 'fake'\n",
        "true['target'] = 'true'\n",
        "newstot = pd.concat([fake, true]).reset_index(drop = True)\n",
        "newstot.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
              "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
              "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
              "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
              "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
              "\n",
              "                                                text subject  \\\n",
              "0  Donald Trump just couldn t wish all Americans ...    News   \n",
              "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
              "2  On Friday, it was revealed that former Milwauk...    News   \n",
              "3  On Christmas day, Donald Trump announced that ...    News   \n",
              "4  Pope Francis used his annual Christmas Day mes...    News   \n",
              "\n",
              "                date target  fake  \n",
              "0  December 31, 2017   fake     1  \n",
              "1  December 31, 2017   fake     1  \n",
              "2  December 30, 2017   fake     1  \n",
              "3  December 29, 2017   fake     1  \n",
              "4  December 25, 2017   fake     1  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>target</th>\n",
              "      <th>fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 30, 2017</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
              "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 29, 2017</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
              "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 25, 2017</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRNcM9pigUJL",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wBqu6PKrgUJM",
        "colab_type": "code",
        "colab": {},
        "outputId": "c91c2b87-0599-49ce-e2b2-203bf5d096bc"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(newstot['text'], newstot.target, test_size=0.2, random_state=2020)\n",
        "\n",
        "pipe = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', LogisticRegression())])\n",
        "\n",
        "model = pipe.fit(x_train, y_train)\n",
        "prediction = model.predict(x_test)\n",
        "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 98.76%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK_gKNk7gUJO",
        "colab_type": "text"
      },
      "source": [
        "# Support Vector Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "whmyeX-NgUJO",
        "colab_type": "code",
        "colab": {},
        "outputId": "922e4b26-c156-4657-97ac-05ceb02995c2"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(newstot['text'], newstot.target, test_size=0.2, random_state=2020)\n",
        "\n",
        "pipe = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', LinearSVC())])\n",
        "\n",
        "model = pipe.fit(x_train, y_train)\n",
        "prediction = model.predict(x_test)\n",
        "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 99.55%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToNTgW7-gUJQ",
        "colab_type": "text"
      },
      "source": [
        "# Multinomial Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "98GCpJIJgUJQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "2911b68c-0d4d-467a-f004-7e66587775f4"
      },
      "source": [
        "pipe = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', MultinomialNB())])\n",
        "\n",
        "model = pipe.fit(x_train, y_train)\n",
        "prediction = model.predict(x_test)\n",
        "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 93.56%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxF5hC1zgUJS",
        "colab_type": "text"
      },
      "source": [
        "# Bernoulli Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cjqSQm5FgUJT",
        "colab_type": "code",
        "colab": {},
        "outputId": "11f64ec8-36f6-4a4d-e498-a7e99392159c"
      },
      "source": [
        "pipe = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', BernoulliNB())])\n",
        "\n",
        "model = pipe.fit(x_train, y_train)\n",
        "prediction = model.predict(x_test)\n",
        "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 94.14%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk4cQxxPgUJV",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Boost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lwYrVj5pgUJV",
        "colab_type": "code",
        "colab": {},
        "outputId": "e30aae27-058a-4c88-a7d8-3a7582ad31d3"
      },
      "source": [
        "pipe = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', GradientBoostingClassifier(loss = 'deviance',\n",
        "                                                   learning_rate = 0.01,\n",
        "                                                   n_estimators = 10,\n",
        "                                                   max_depth = 5,\n",
        "                                                   random_state=55))])\n",
        "\n",
        "model = pipe.fit(x_train, y_train)\n",
        "prediction = model.predict(x_test)\n",
        "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 99.52%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84yJLZyjgUJY",
        "colab_type": "text"
      },
      "source": [
        "# XGBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QzZiIHS7gUJY",
        "colab_type": "code",
        "colab": {},
        "outputId": "630193d3-165a-4a7d-c917-2dcdc133c652"
      },
      "source": [
        "pipe = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', XGBClassifier(loss = 'deviance',\n",
        "                                                   learning_rate = 0.01,\n",
        "                                                   n_estimators = 10,\n",
        "                                                   max_depth = 5,\n",
        "                                                   random_state=2020))])\n",
        "\n",
        "model = pipe.fit(x_train, y_train)\n",
        "prediction = model.predict(x_test)\n",
        "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 99.52%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VMlu-OAgUJa",
        "colab_type": "text"
      },
      "source": [
        "# Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_cDvPkizgUJa",
        "colab_type": "code",
        "colab": {},
        "outputId": "e38d935b-01ac-42c9-ed8d-e4d4f7868633"
      },
      "source": [
        "pipe = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', SGDClassifier())])\n",
        "\n",
        "model = pipe.fit(x_train, y_train)\n",
        "prediction = model.predict(x_test)\n",
        "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 99.12%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1xmABpNgUJc",
        "colab_type": "text"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QgPuyN7YgUJc",
        "colab_type": "code",
        "colab": {},
        "outputId": "abd83f21-d518-4d6f-a8e4-3008f1b1fe8b"
      },
      "source": [
        "pipe = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', DecisionTreeClassifier(criterion= 'entropy',\n",
        "                                           max_depth = 10, \n",
        "                                           splitter='best', \n",
        "                                           random_state=2020))])\n",
        "\n",
        "model = pipe.fit(x_train, y_train)\n",
        "prediction = model.predict(x_test)\n",
        "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 99.55%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-88yLE2gUJe",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MtfSCVKhgUJf",
        "colab_type": "code",
        "colab": {},
        "outputId": "482f73e5-0f6c-466b-8515-b1206cb4ab0e"
      },
      "source": [
        "pipe = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', RandomForestClassifier())])\n",
        "\n",
        "model = pipe.fit(x_train, y_train)\n",
        "prediction = model.predict(x_test)\n",
        "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 98.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KSxugy9gUJh",
        "colab_type": "text"
      },
      "source": [
        "# KNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZCXVu268gUJh",
        "colab_type": "code",
        "colab": {},
        "outputId": "d12e4970-a42c-42d0-a703-f1d4d2aa05ef"
      },
      "source": [
        "pipe = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', KNeighborsClassifier(n_neighbors = 10,weights = 'distance',algorithm = 'brute'))])\n",
        "\n",
        "model = pipe.fit(x_train, y_train)\n",
        "prediction = model.predict(x_test)\n",
        "print(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 67.59%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v6HRHYdgUJj",
        "colab_type": "text"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2VU3nO79gUJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = newstot.text\n",
        "Y = newstot.target\n",
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(Y)\n",
        "Y = Y.reshape(-1,1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "or38pW4sgUJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)\n",
        "max_words = 500\n",
        "max_len = 75\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X_train)\n",
        "sequences = tok.texts_to_sequences(X_train)\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
        "def RNN():\n",
        "    inputs = Input(name='inputs',shape=[max_len])\n",
        "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "    layer = LSTM(64)(layer)\n",
        "    layer = Dense(256,name='FC1')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = Dropout(0.5)(layer)\n",
        "    layer = Dense(1,name='out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "    model = Model(inputs=inputs,outputs=layer)\n",
        "    return model\n",
        "model = RNN()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8Y5sd4-WgUJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import plot_model \n",
        "plot_model(model, to_file='model1.png')\n",
        "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fnbKRWLygUJp",
        "colab_type": "code",
        "colab": {},
        "outputId": "bdcd4e41-2331-4ed8-afe1-50d61c9f4105"
      },
      "source": [
        "model.fit(sequences_matrix,Y_train,batch_size=256,epochs=10,\n",
        "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 30530 samples, validate on 7633 samples\n",
            "Epoch 1/10\n",
            "30530/30530 [==============================] - 28s 905us/step - loss: 0.2086 - accuracy: 0.9200 - val_loss: 0.1176 - val_accuracy: 0.9583\n",
            "Epoch 2/10\n",
            "30530/30530 [==============================] - 27s 880us/step - loss: 0.0821 - accuracy: 0.9708 - val_loss: 0.0869 - val_accuracy: 0.9707\n",
            "Epoch 3/10\n",
            "30530/30530 [==============================] - 33s 1ms/step - loss: 0.0687 - accuracy: 0.9752 - val_loss: 0.0746 - val_accuracy: 0.9752\n",
            "Epoch 4/10\n",
            "30530/30530 [==============================] - 27s 882us/step - loss: 0.0590 - accuracy: 0.9791 - val_loss: 0.0835 - val_accuracy: 0.9730\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f987cdeea90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3IygSHaZgUJr",
        "colab_type": "code",
        "colab": {},
        "outputId": "197da09a-d82f-4fba-9955-4958514069d5"
      },
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
        "accr = model.evaluate(test_sequences_matrix,Y_test)\n",
        "print('Accuracy: {:0.2f}'.format(accr[1]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6735/6735 [==============================] - 3s 488us/step\n",
            "Accuracy: 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ryOFAjGCgUJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}